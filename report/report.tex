\documentclass[journal,twocolumn,american]{IEEEtran}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{calc}
\renewcommand{\ttdefault}{cmtt}

\ifx\mmCfgTodos\undefined
    \usepackage[disable]{todonotes}
\else
    \usepackage{todonotes}
    \newcommand{\tinierForTODOs}{\fontsize{6}{0}\selectfont}
    \setuptodonotes{size=\tinierForTODOs,noinlinepar,inlinewidth=2in,tickmarkheight=0.1cm}
\fi

% via https://stackoverflow.com/a/123184/8762161
\newlength{\mmdfigureWidthTmp}

\newcommand{\mmdfigure}[2]{\begin{figure}[h]%
    % get the width of the figure unscaled %
    \settowidth{\mmdfigureWidthTmp}{\includegraphics{#1.mmd.pdf}}%
    % give the diagrams a constant scale down regardless of their size. %
    % (based on a rough conversion between their font sizes, assuming i'm correct about those. -amgg) %
    \setlength{\mmdfigureWidthTmp}{\mmdfigureWidthTmp*10/16}%
    % scale that down further but only if necissary to not exceed text width %
    % (note that we use columnwidth here, not textwidth, since we're in a 2-column layout) %
    \setlength{\mmdfigureWidthTmp}{\minof{\mmdfigureWidthTmp}{\columnwidth}}%
    \centering%
    \includegraphics[width=\mmdfigureWidthTmp]{#1.mmd.pdf}%
    \caption{#2}%
\end{figure}%
}

\newcommand{\mmdfiguretodo}[2]{\begin{figure}[h]%
    \centering%
    \missingfigure{#1}%
    \caption{#2}%
\end{figure}%
}

\ifx\mmCfgNofigures\undefined
\else
    \renewcommand{\mmdfigure}[2]{}
    \renewcommand{\mmdfiguretodo}[2]{}
\fi

\begin{document}

% title stuff
\title{Monkey Minder}
\author{%
Caleb~Fringer~(016632603,~caleb.fringer@sjsu.edu)\\%
Adrian~Guerra~(0123456789,~adrian.guerra@sjsu.edu)\\%
Dhananjay~Surti~(019111482,~dhananjay.surti@sjsu.edu)%
}
\maketitle

\todo[inline]{student ids at top of page}

\listoftodos

\section{Goals and Motivation}
The goal of our project is to implement a distributed tree-based data store similar
to Apache ZooKeeper using Golang. Like ZooKeeper, our service guarantees linearizable 
writes while supporting read-heavy workloads by guaranteeing montonic reads.
Developing such a service involves implementing protocols for leader election, 
replication \& consistency, and Lamport timestamps to provide causal ordering.
The service must be fault-tolerant, robust to network partitions, and available to 
many concurrent clients.

For our implementation, we wanted to adhere to a few additional constraints. First,
we chose to use Golang as our programming environment. Golang adopts the
Communicating Sequential Processes (CSP) concurrency model, and we chose to fully
embrace this paradigm in our implementation by avoiding locks, semaphores, and other
concurrency primitives. Instead, we relied almost exclusively on Go's channel primitive
for managing concurrent access to shared resources.

Second, instead of Zab we chose to utilize the Raft consensus algorithm. While
Zab and Raft are both equivalent to Paxos \todo{CITE}, Raft is more recent algorithm
and used in popular services such as etcd and MongoDB \todo{CITE}. Additionally, 
Raft claims to be a more understandable alternative to Paxos, a property that proved
to make implementation easier. In order to use Raft, we had to relax its consistency
guarnatee for reads, which provides for linearizable reads by forwarding all requests
to the leader. ZooKeeper only provides monotonic reads from the perspective of 
individual clients. We modified our Raft implementation to allow reads to be served 
locally from each replica, enabling high throughput for read-dominant workloads.

Third, we chose to use gRPC and Protocol buffers as our transport layer. gRPC is
an RPC framework created by Google \todo{CITE}, and Protobufs are Google's language 
independent serialization framework \todo{CITE}. We chose these tools due to their
popularity in the industry and our desire to become acquainted with tools that
we may encounter later in our careers.

By building our project within these parameters, we hoped to gain practical
experience navigating the unique challenges posed by distributed systems.

\section{Challenges Addressed}
While building our Zookeeper-like service, we had to address multiple fundamental distributed system challenges.
These challenges shaped the requirements and constraints of our system and influenced the design decisions described in
detail in the Design section.

Fundamental to our system is the issue of \textbf{consistency}. In a distributed environment with concurrent clients and 
asynchronous communication, ensuring that all nodes observe a coherent view of the shared state is non-trivial.
Without careful coordination, concurrent updates could lead to divergent replicas, fractured writes, or stale reads.
We addressed this concern by strictly adhering to the Raft protocol. As long as one leader is only ever responsible
for updating the global state, we can ensure that changes to the state are \textbf{linearizable}. Furthermore, by
ensuring that these updates are durable, we can guarantee \textbf{monotonic reads} to clients with respect to the
global state. Once an update is committed, it can never be deleted. While clients may read stale data, the data
they read will preserve the causal relationship of state updates.

Our system is \textbf{fault tolerant}. Individual nodes may crash, restart with stale state, or 
fail to communicate due to partitions. Our system must continue making progress despite these failures
and must guarantee that committed updates are never lost or partially applied. Achieving fault tolerance while 
preserving strong consistency imposed strict requirements on how nodes coordinate, elect leaders, and recover 
from failures.

\textbf{Concurrency} is also an essential challenge. Individual nodes in our system process many requests simultaneously, 
each competing for access to a shared global state. Without a proper serialization of requests, concurrent operations could 
produce non-deterministic outcomes. This is especially relevant for operations like create, update, and delete, which must 
appear atomic to clients. We addressed this by ensuring that each server node processes client requests in the order
received, and that if a server processes a write request, it does not process any other request until the write is complete.
This ensures that client transactions are serialized with respect to individual servers.

Our service is designed to be \textbf{scalable}. As the number of clients and nodes grows, the system maintains
high throughput, especially for read-dominant workloads. ZooKeeper, which our project is based upon, is designed
to support concurrent read requests by allowing replication to naturally load-balance client requests. Since our
system can scale horizontally as replicas are added to the cluster, this naturally supports high availability and 
throughput. An added benefit of this is that as our system scales, it becomes more fault tolerant as fewer nodes
are required to be available to ensure correct operation of the server.

Furthermore, our system is \textbf{transparent}. Clients do not need to know which node is the current leader, 
whether a failover has occured, or how the system internally coordinates. Masking operational details 
simplifies the client interface and reduces risk of incorrect client behavior.

Finally, \textbf{heterogeneity and openness} are an essential feature of our system. By using language \& platform agnostic
tools like gRPC, Protobufs, and GoLang, our system can communicate with any client that implements our service API using
our RPC definitions. Golang, while being a compiled language, supports a lot of abstraction over the underlying operating
system. As a result, any platform with a Go compiler can run our server software and participate in a cluster. Additionally,
because all of our service APIs are defined in the Protobuf format, additional APIs can be added on top of our core service
without much modification to the consensus layer.

\section{Prior Art}
Zookeeper achieves consensus through the Zookeeper Atomic Broadcast (Zab)
protocol, which is a leader-based atomic broadcast system designed to ensure
consistent state replication across nodes [1]. Zab shares some conceptual similarities
with the Raft algorithm, such as leader election and log replication, but was developed
independently [3]. Since Raft has become widely adopted and is designed to be
understandable, we will elect to use Raft to provide both leader election and
consistency in our implementation.
Much research has been done to improve the performance and consistency of Raft
under failure scenarios. For instance, in [4] Kim et al. explored improving leader-based
consensus algorithms such as Raft using federated learning to enhance stability and
performance. Furthermore, Liu et. al has suggested improvements in both performance
and strict consistency guarantees over the original Raft algorithm by requiring strong
consistency of followers logs [5]. They show that their accelerated log backtracking Raft
algorithm can reduce the number of RPCs required to resolve log conflicts under
multiple leader election failure scenarios [5]. Similarly, Liu et Al. (2023) propose an
optimized Raft algorithm (SS-Raft) that incorporates snapshot-based log compression
to reduce excessive log growth during replication and improve recovery under unreliable
networks and churn failures [6]. Finally, Paznikov et. al proposes a leaderless approach
to atomic broadcast using the actor model of concurrency [7]; while the actor model
approach is appealing to us, we think designing a ZooKeeper service around the actor
model is a more appropriate topic for subsequent research projects.
Building on these ideas, our project will use Raft atomic broadcast to achieve strong
consistency among replicas. In particular, we draw inspiration from recent research
such as [8], which demonstrates that atomic broadcast can be achieved efficiently
through a reduction from multivalued Byzantine Agreement (MBA) while avoiding heavy
cryptographic signatures, and from [9] S. Mane et. al which proposes additions to
ZooKeeper which give it better resilience against Byzantine faults.

\section{Design}
Our design takes into account the distributed systems challenges of heterogeneity,
openness, security, failure handling, concurrency, quality of service and scalability.

\textbf{Heterogeneity}:
We expose our service via gRPC with Protocol Buffers, which provides a language-agnostic, 
platform-agnostic interface for clients to interact between clients and servers. The Raft
server implements the \texttt{RaftServer} gRPC service and uses generated stubs on both the 
server and client side, allowing future clients to be written in any language supported by
gRPC without changing the core consensus implementation.\todo{Have some sort of citation maybe}

\textbf{Openness}:
The system is designed as a set of composable modules: the replicated log (\texttt{Log}), the
tree-based data store (\texttt{Tree}), and the Raft consensus layer (\texttt{RaftServer}). The
log is generic over the entry snapshot types and only depends on an abstract \texttt{Snapshot}
interface, so other state machines (besides our ZooKeeper-like tree) can be plugged in 
without changing the Raft code.

\textbf{Security}:
At the transport layer we use gRPC, which supports mutual TLS for channel encryption and
authentication. In the current prototype, we use insecure credentials for simplicity, but
the design isolates transport setup inside \texttt{connectToPeers}, so adding TLS in the future
will be straightforward.

\textbf{Failure Handling}:
Raft provides deterministic leader election and log replication under crash failures.
The follower nodes use randomized election timeouts to avoid split votes, and step up to
the candidate role when they stop hearing from a leader. Candidates send \texttt{RequestVote}
RPCs in parallel and step own when they see a higher term, while leaders periodically
send empty \texttt{AppendEntries} (heartbeats) and perform log backtracking and truncation when
followers' logs diverge.

\textbf{Concurrency}:
Each node runs a single Raft loop(\texttt{doLoop}) that dispatches into role-specific
loops (\texttt{doFollower}, \texttt{doCandidate}, \texttt{doLeader}). These loops serialize
all consensus state transitions. RPC handlers for \texttt{RequestVote} and \texttt{AppendEntries}
only enqueue requests on channels and block waiting for responses, which keeps Raft state
changes confined to the state machine goroutine. Parallelism is used only for outbound RPCs
(e.g, parallel vote requests and AppendEntries to followers), ensuring a simple, mostly single-threaded
correctness story while still utilizing concurrency for I/O.

\textbf{Quality of Service}:
Randomized election timeouts limit unecessary split vites, while periodic heartbeats prevent
unnecessary elections during normal operation. The log module supports compaction (squashing)
and snapshotting so that old entries can be removed once safely replicated and applied, which
bounds memory usage and keeps replication latency low during long-running workloads.

\textbf{Scalability}:
The system scales horizontally by adding more Raft servers to the cluster. Clients talk to
any node in the cluster\todo{MIGHT NEED TO CHANGE THIS}. Reads and writes are internally forwarded
to the current leader, which serializes updates and replicates them to followers using AppendEntries.
Because the replicated log is generic, different state machines can be plugged in to support different
workloads without changing the consensus layer.

\textbf{Transparency}:
Clients interact with the system as if it were a single, ZooKeeper-like service with a heirarchical
namespace. They are don't know which node is currently the leader, when failovers occur, or how many replicas
exist in the cluster. Leader elecion, log replication, and commit-index management are all hidden behind the
API, providing failure transparency and location transparency.

\subsection{Key Components and Algorithms}

\subsubsection{RaftServer and Node Roles}
The \texttt{RaftServer} type represents a single Raft node. It maintains the node identity (\texttt{Id}), peer addresses,
current role (\texttt{FOLLOWER}, \texttt{CANDIDATE}, \texttt{LEADER}), current term, the node it voted for,
gRPC server state, a replicated log, and per-RPC channels for AppendEntries and RequestVote. 

The lifecycle is driven by the \texttt{doLoop}, which dispatches to state-specific loops. The {doFollower}
loop waits for AppendEntries and RequestVote requests. It resets its election timer on each valid interaction.
If the timer expires, the node promotes itself to \texttt{CANDIDATE}. The \texttt{doCandidate} loop handles all the
logic for the voting mechanism during leader election. It increments its term, votes for itself, and sends parallel
RequestVote RPCs to all peers. The \texttt{CANDIDATE} becomes \texttt{LEADER} upon winning a majority.
It reverts to \texttt{FOLLOWER} if it sees a higher term, or restarts the election on timeout. The \texttt{doLeader}
loop manages per-follower replication pointers (\texttt{nextIndex} and \texttt{matchIndex}). It sends AppendEntries
heartbeats and log entires, and responds to vote and AppendEntries RPCs from other nodes, stepping down when observing a higher
term.

\subsubsection{Log and Snapshot Module}
The replicated log is implemented as a generic, snapshot-aware data structure with an entry and a snapshot type.
This enables easy integration with our heirarchical tree data store.
The replicated log maintains the following:
(i) a \texttt{headSnapshot} representing the state up to the first stored entry,
(ii) a \texttt{tailSnapshot} that is updated as new entries are appended,
(iii) an index offset for the first logical entry,
(iv) the slice of entries, and
(v) a commit index.

Appending an entry to the log involves two steps. First, the entry is applied to
the \texttt{tailSnapshot}, producing an updated state that reflects the new
operation. Second, the entry is appended to the in-memory list of log entries.
This ensures that the tail snapshot always reflects the state obtained by
applying all log entries in order, simplifying state-machine replication.

The log supports multiple retrieval methods, including \texttt{GetEntryAt} and
\texttt{GetEntryLatest}, which provide direct indexed access to entries or the
most recently appended entry. These operations are crucial during leader
election, where candidates must advertise their last log index and term, and
during replication, where followers verify that their local logs agree with the
leader’s prefix.

To prevent unbounded growth, the log implements compaction operations.
\texttt{SquashFirstN} applies the first \(n\) entries in the log to the
\texttt{headSnapshot} and removes them from memory, effectively shortening the
log without losing state. \texttt{SquashUntil} performs a similar compaction
based on a predicate evaluated over log entries. These mechanisms mimic
snapshotting in production Raft systems and allow long-running clusters to avoid
excessive memory usage.

Truncation is handled through the \texttt{TruncateAt} method, which removes log 
entries at and beyond a specfied index after first rebuilding the \texttt{tailSnapshot}
using the nearest snapshot at or below the index. Raft leaders use this function to repair
logs on followers that have diverged from the leader's log due to incomplete replication or
outdated state.

\subsubsection{Application-Level Command Processing}

Client operations are expressed as implementations of the \texttt{ClientMessage} interface. Each message type(
\texttt{Create}, \texttt{Delete}, \texttt{SetData}, \texttt{Exists}, \texttt{GetData}, and \texttt{GetChildren}) 
encapsulates the semantics of a client request. Messages specify whether they must run on the leader (\texttt{IsLeaderOnly}) and define how to produce new log
entries through \texttt{DoMessage}. Read-only commands generate no log entries and operate directly on the snapshot of the tree maintained by the server. By contrast, write operations produce a list of \texttt{LogEntry} structures that
the leader appends to the log and replicates across the cluster.

Our design intentionally separates the applicaiton logic from Raft's consensus logic. Raft guarantees
the order and durability of log entries, while the message handlers guarantee deterministic state transitions
for the Tree data store.

\subsubsection{Watch Manager}

The system provides lightweight watch functionality similar to Zookeeper's. Each watch consists of a predicate
tested against committed log entries. When a committed entry satisfies a watch predicate, the associated callback
channel is fired and the watch is removed. Watches are checked during leader commit processing. This ensures that
notifications reflect globally committed state.

\subsubsection{Tree State Machine}
The state machine that is replicated by Raft is a heirarchical \texttt{Tree} structure that closely
models Zookeeper's znode abstraction. Each node in the tree has a name, associated data, a version number, and a set of children.
Operations such as \texttt{Create}, \texttt{Update}, and \texttt{Delete} modify the tree deterministically.
Because these operations are deterministic and their arguments are captured precisely in \texttt{LogEntry} values,
every replica applying the same sequence of committed log entries converges to the same logical state.

The \texttt{ApplyEntry} method maps log entries to concrete tree operations. This strict determinism is the foundation
of correct state machine replication.
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=2.5in]{test-uml.mmd.pdf}
%     \caption{Hello world.}
% \end{figure}

\todo[inline]{Need to finish this section with the diagrams}
\subsection{Architecture and Component Interaction}

Our system follows a replicated state-machine architecture built around a
Raft cluster. The clients interact with what looks like a single
centralized data store service, while internally the service is replicated across
multiple Raft servers for fault tolerance and consistency.

Each server process embeds three main subsystems: a client-facing RPC layer, the
Raft consensus module, and the replicated data store tree. The RPC layer terminates
gRPC/Protocol Buffer requests from clients and converts them into typed
\texttt{ClientMessage} objects. These messages are then processed by the local
Raft instance. For write operations (such as \texttt{Create}, \texttt{SetData},
and \texttt{Delete}), the server’s Raft leader appends a corresponding
\texttt{LogEntry} to its log, replicates the entry to followers via
\texttt{AppendEntries} RPCs, and, once a majority have acknowledged the entry,
commits it and applies it to the tree state machine. Read-only operations
(\texttt{Exists}, \texttt{GetData}, \texttt{GetChildren}) can be served by any
node using its committed snapshot, while leader-only operations are forwarded
internally to the current leader.

From the client’s point of view, all of this complexity is hidden (transparency). Clients
connect to any server, issue operations against a hierarchical namespace, and
receive responses that reflect a linearizable history of writes and monotonic
reads. Leader election, log replication, commit-index management, and watch
delivery all occur behind the scenes within the Raft layer.

\subsubsection{Use-Case View}

Figure~\ref{fig:usecase} presents a use-case style view of the system from the
client’s perspective. The primary actor is a generic client application that
interacts with the our data service. The main use cases include
creating znodes, updating data, reading data, listing children, deleting znodes,
and registering watches for changes. An operator or administrator actor may
perform management-oriented operations such as enumerating znodes or cleaning up
application state.

\mmdfiguretodo{usecase-overview}{System use-case overview.\label{fig:usecase}}

This diagram emphasizes that clients treat the service as a single logical
coordination point, even though it is backed by multiple Raft replicas.

\subsubsection{Deployment and Component View}

Figure~\ref{fig:deployment} shows a combined deployment and component view of
the system. On the left, client processes (e.g., our Go client tool) run on
arbitrary hosts and open gRPC connections to any server in the Raft cluster. On
the right, the cluster consists of three to five \texttt{RaftServer} processes,
each hosting:

\begin{itemize}
  \item a \emph{ClientSession} component, which terminates client RPCs and
        translates them into \texttt{ClientMessage} instances,
  \item the \emph{Raft core}, which implements leader election, term tracking,
        log replication, and commit-index advancement, and
  \item the \emph{Tree state machine}, which applies committed log entries to
        maintain the hierarchical znode namespace.
\end{itemize}

Servers communicate with each other exclusively via Raft RPCs
(\texttt{RequestVote} and \texttt{AppendEntries}) over gRPC channels. The
underlying network is assumed to provide reliable message delivery with possible
delays, reordering, and crash-stop failures.

\mmdfiguretodo{deployment}{Cluster deployment and component diagram.\label{fig:deployment}}

This diagram highlights both the physical layout (distributed servers and
clients) and the logical decomposition of each server process into components.

\subsubsection{Dynamic Interaction and Sequence Views}

Figures~\ref{fig:raft-election} and~\ref{fig:raft-rpc-flow} focus on the dynamic
behavior of the Raft layer. Figure~\ref{fig:raft-election} is a state-oriented
view of a single server’s role transitions among \texttt{FOLLOWER},
\texttt{CANDIDATE}, and \texttt{LEADER}. It shows how randomized election
timeouts, vote requests, and heartbeats cause nodes to move between states.

Figure~\ref{fig:raft-rpc-flow} complements this with a sequence-style view of
message exchanges during a leader election. A follower’s election timeout
expires, it begins sending \texttt{RequestVote} RPCs, and, once it receives a majority of votes, it transitions
to the leader state and starts sending \texttt{AppendEntries} heartbeats. These diagrams together illustrate the
interaction between components and the temporal ordering of messages that
establish a single, authoritative leader in each term.

Finally, the write path from client to replicated tree follows a similar sequence: the client sends a request to the leader; the leader appends the
corresponding log entry, replicates it to followers using \texttt{AppendEntries}, waits for a majority of successful 
responses, advances the commit index, applies
the entry to the local tree, triggers any relevant watches, and then replies to the client. This sequence ensures that externally visible
state always reflectscommitted, majority-replicated updates.

\subsection{Log}
\mmdfigure{log-diagram}{Log UML}
\mmdfigure{log-diagram-structure}{Log structure}

We opt to implement more general, generic log API which is suitable for our use case,
and then build the specific functionality we need on top of that.
Our \texttt{Log} consists of entries, snapshots, and checkpoints.
\subsubsection{Interfaces}
To make Log work with one's data types, a corresponding \textit{Entry} type must be created and the \textit{Snapshot} interface must be implemented.

An \textit{Entry} is a single element in the log, in other words, it is an object representing a single modification.
Entries can be appended to the end of the log with \texttt{log.Append(entry)} and accessed with either \texttt{log.GetEntryAt(index)} or \texttt{log.GetEntryLatest()}.
There is no actual interface corresponding to \textit{Entry}, rather, it is whatever type is accepted by the \textit{Snapshot}'s \texttt{Append} method (see below).

A \textit{Snapshot} represents the full state of the system at a given entry in the log.
Data types implementing the \texttt{Snapshot} interface need only provide a \texttt{Clone()} method, and a \texttt{Append(entry)} method which makes the corresponding change to itself in-place.

\subsubsection{Log Functionality}
Logs track two primary snapshots: a \textit{head snapshot} representing the state before any changes were made, and a \textit{tail snapshot} representing the state after all changes have been made.
When an entry is appended to the log, as well as adding the entry to its internal list of entries, the log also applies the entry to its tail snapshot.

Keeping both snapshots allows us to roll back certain log entries if necessary without storing the state at every entry,
but still allowing for $O(1)$ access to the current state.
\subsubsection{Checkpoints}
In practice, we do not only care about tracking of (and efficient access to) the state at the end of the log,
we also need to get those same things for the point partway through the which has definitely been committed.

To this end, we implement a system of \textit{Checkpoints}, in which a \textit{Checkpoint}:
\begin{itemize}
    \item Sits at some logical point along the log. (Which is to say that it either sits at an index corresponding to an entry already in the log, or else sits at the logical position at the start of the log, before all entries.)
    \item Can be advanced from its current position to a later position in the log. (Checkpoints \textbf{cannot} be moved backwards)
    \item Tracks an additional \textit{Snapshot} at its position, providing the user $O(1)$ access to the state at its position, as well as providing the log a more recent spot from which to begin re-creating the tail snapshot when entries are removed.
    \item Forbids removing its corresponding entry, or any entries before that, from the log.
\end{itemize}


\section{Evaluation}
\subsection {Approach Evaluation}
Our system uses Raft-based replication to implement a strongly consistent metadata store.
Our approach is appropriate because Raft provides a well-specified, leader-driven consensus protocol that is easier
to implement correctly than Paxos while providing equivalent safety guaranteed. The system obtains linearizable writes,
monotonic reads, and crash-failure tolerance through its use of term-based leader election, quorum-based log replication,
ans a state machine driven replicated log.

Raft's correctness is due to the following:
(1) at most one leader is elected per term
(2) leaders never overrite committed log entries,
(3) the log-matching property ensures all prefixes of log converge.
Our implementation enforces these through:
\begin{itemize}
    \item \textbf{Randomized election timeouts} (\texttt{DEFAULT\_MIN\_TIMEOUT}-\texttt{DEFAULT\_MAX\_TIMEOUT}) ensuring split-vote resolution.
    \item \textbf{Term discipline}: RPC handlers check and update terms, forcing candidates and leaders to revert to followers on higher terms.
    \item \textbf{Log matching \& conflict repair}: followers reject mismatched \texttt{prevLogIndex}/\texttt{prevLogTerm} and truncate to the last matching prefix via \texttt{reconcileLogs()}.
    \item \textbf{Commit index advancement}: leaders compute the majority-replicated index across followers and safely advance commit state.
    \item \textbf{State machine application}: committed entries are applied to the heirarchical tree structire, maintaining deterministic state evolution across replicas.
\end{itemize}

The algorithmic complexity reflects standard Raft complexity:
\begin{itemize}
    \item Leader election completes in $O(n)$ messages.
    \item Log replication is $O(k)$ for $k$ new entries, with conflict repair costing up to $O(\ell)$ in worst case log-divergence.
    \item Steady-state operation requires $O(n)$ heartbeats per period.
    \item State lookups in the tree operates in $O(h)$ where $h$ is the path depth.
\end{itemize}

Raft's simplicity allowed us to write a clean, channel-driven state machine in Go, where all the consensus dependant transitions occur in a
single goroutine (\texttt{doFollower}, \texttt{doCandidate}, \texttt{doLeader}).
This eliminates races in shared data without requiring explicit locks.

\subsection{Evaluation of Key Distributed-System Properties}

\subsubsection{Fault Tolerance}

Our system tolerates crash failures of leaders and followers by a combination of mechanisms. Followers use randomized election timeouts to detect leader failures and
step up to candidates, which starts the leader election mechanism. Regardless of which state a node is in, it will revert to a follower once
it receives an RPC with a higher term. Since every log entry is committed only when acknowledged by a majority, any commmitted update is guaranteed to survive
leader crashes. 

If a leader crashes before commit, followers do not expose the uncommitted update. If it crashes after commit, the new leader preserves the entry
because it has already recorded i. This matches Raft's safety guaranees and is validated through our test cases (Test cases 6, 7). 

\subsubsection{Performance}

We have several design choices that optimize low-latency and high throughput. Our replication is fully pipelined: Our leader issues AppendEntries RPCs.
concurrently to all peers, and followers respond asynchronously. The leader's inner loop is non-blocking except when waiting on
client-related watches that ensure linearizability for leader-only operations.

Reads are also efficiently processed. Non-mutating requests (\texttt{GetData}), \texttt{GetChildren} are handled locally by any follower
without contacting the leader, significantly reducing load on the leader. This separation between read and write paths 
reduces bottlenecks.

\subsubsection{Scalability}
The system scales horizontally using more Raft nodes. Writes cost $O(n)$ messages but remain performant for typical 
quorum sizes (3-7 nodes). Reads scale nearly linearly because they can be served by any follower for non-mutating requests.
The log layer supports compaction (\texttt{SquashFirstN}, \texttt{TruncateAt}) ensuring logs don't grow unbounded.

\subsubsection{Consistency}

We acheive \textbf{linearizable writes} and \textbf{monotonic reads} in our system. One of the factors that let us acheive this is the
leader-serialization of all client updates. The other important factor is the strict-prefix agreement enforced by \texttt{doCommonAE()} 
and \texttt{reconcileLogs()}, which ensures that followers never diverge from the leader's log. Finally, followers apply committed entries
strictly in order through log checkpoints.

%% --------------------- IMPLEMENTATION DETAILS HERE ---------------------
\section{Implementation Details}
Our implementation is divided into two main layers: the Client API Layer and the Consensus Layer.

\subsection{Client API Layer}
The client layer provides several endpoints for interacting with the system. These include operations for creating, deleting, and checking the existence of paths, as well as retrieving and setting data. Additionally, clients can retrieve children of a path and synchronize their state with the server.


\subsection{Consensus Layer}
The consensus layer is built on the Raft protocol, replacing Zookeeper's Zab protocol. It operates with three distinct node states: Follower, Leader, and Candidate.
Each node runs a state machine that delegates tasks to the appropriate handler based on its current role in the cluster.

\subsubsection{Process Models and Types}
Our Raft node is implemented by \texttt{ElectionServer}, which contains the node identity (\texttt{Id}), transport configuration (\texttt{Port}, \texttt{peers}),
local state (\texttt{state}) $\in$ \{\texttt{FOLLOWER}, \texttt{CANDIDATE}, \texttt{LEADER}\}, and protocol variables (\texttt{term} and \texttt{logIndex}). We define
strongly-types aliases for clairty:
\texttt{Term} and \texttt{LogIndex} (\texttt{uint64}), and \texttt{NodeId} (\texttt{uint64}).

The server exposes the Raft RPC through gRPC (service \texttt{ElectionServer}).
Inbound RPCs are separated into internal channels:
\texttt{aeRequestChan/aeResponseChan} for AppendEntries and \texttt{rvRequestChan/rvResponseChan} for RequestVote.

\subsubsection{Lifecycle and Event Loop}
The method \texttt{Serve()} performs three responsibilities:
(i) create a TCP listener on \texttt{localhost:\$\{Port\}},
(ii) construct and register a gRPC server that binds the Raft RPC handlers,
and (iii) spawns the node's control loop \texttt{doLoop(ctx)} which drives the Raft state machine.

\texttt{doLoop} runs forever, redirecting to one of \texttt{doFollower}, \texttt{doCandidate}, or 
\texttt{doLeader} based on \texttt{state}. Each state handler is a blocking loop selecting over protocol
events (RPCs) and timers, and exits only when a state transition occurs (e.g. timeout, quorum win, or term regression). This makes sure 
that only one state handler is active at a time.

\subsubsection{Timers and Failure Detector (Raft \S5.2)}
We implement a randomized election timeout using
\texttt{getNewElectionTimer()}, which draws uniformly from
$[1500,2000]\,$ms. The node resets this timer on any leader activity
(a valid AppendEntries) or on serving a RequestVote, matching the “leader
stickiness” property of Raft. The heartbeat period is set to
\texttt{DEFAULT\_HEARTBEAT\_TIMEOUT}$=750\,$ms; leaders refresh this
periodically to prevent follower timeouts.

\subsubsection{RPC Handler Boundary}
Inbound RPCs (\texttt{AppendEntries}, \texttt{RequestVote}) are thin on purpose: they push the 
immutable request onto the corresponding request channel and block on the response channel. The state
machine consumes these requests inside the current role's loop, generates the reply, and sends it back.
This preserves a single point of serialization for correctness and simplifies concurrency reasoning
(network threads never mutate the Raft state directly).

\subsubsection{Term Management and Common Logic (\S5.1)}
Both RPC paths share "common" characteristics implemented in \texttt{doCommonAE} and \texttt{doCommonRV}:

\begin{itemize}
    \item \textbf{Monotonic terms}: If a request carries a term $T > $ \texttt{s.term},
    the server marks \emph{staleTerm/shouldAbdicate} and defers \texttt{s.term = T} until
    the response is composed; the caller (state loop) then transitions to \texttt{FOLLOWER}
    as needed. Replies always include the server's current term.

    \item \textbf{Reject stale terms}: If $T < \texttt{s.term}$ the server rejects.
\end{itemize}

This shared handlign ensures both RPC types correctly implement Raft's term
invariant regardless of current role.

\subsubsection{AppendEntries Path (Follower \& Leader, \S5.3)}
The \texttt{AppendEntries} RPC is implemented as a wrapper around the \texttt{doCommonAE} helper. The RPC handler
forwards the request onto \texttt{aeRequestChan} and waits on \texttt{aeResponseChan}, so that all log and term
changes are serialied inside the Raft state loop.

Inside \texttt{doCommonAE}, the server first enforces Raft's term rules. If the incoming request carries a higher term,
the node updates its \texttt{term}, clears \texttt{votedFor}, and records the sender as the current leader before creating 
a response. If the request term is stale, the server immediately returns \texttt{Success=false}.

Next the follower checks log consistency with the leader. It calculates the index of its last local entry and 
compares it with the \texttt{prevLogIndex} thats provided by the leader. If the follower's log is shorter than this index,
or if the term at \texttt{prevLogIndex} does not match \texttt{prevLogTerm}, the follower rejets the RPC with 
\texttt{Success=false}, indicating that the leader must backup and retry from an earlier prefix.

When the prefix check succeeds, the follower calls \texttt{reconcileLogs} to repair any divergent suffixes. This helper
scans new entries and either: 
(i) appends entries beyond the end of the local log, or
(ii) truncates the local log at the first conflicting index and then appends all remaining entries from the leader.
This realizes Raft's ``conflicting entries are overwritten'' rule while minimiing unnecessary truncation.

Finally, the follower advances its commit point. It sets the commit index to \(\min(\texttt{leaderCommit}, \)) and 
uses the \texttt{commitPoint} checkpoint object to apply any newly commmitted entries to the tree state machine and fire watches.
This ensures that committed state is monotonic and identical across all replicas.


\subsubsection{RequestVote Path (Follower \& Candidate, \S5.2, \S5.4)}
The \texttt{doCommonRV} routine implements the main Raft voting rules. When a 
RequestVote RPC arrives, the server first checks the candidate's term and immediately
adopts it. It reverts to the follower state if the candidate's term is higher. Then it
enforces Raft's one vote per term requirement by granting a vote only when the server has
not voted in the current term or when its prior vote was already vast for the same candidate. 
Finally, it checks if the candidate's log is up to date as required by Raft.
This comparison uses the \texttt{LastLog.AtLeastAsUpToDateAs} method, which first compares Log
terms and uses the log index as the tiebreaker. Only candidates whose logs are at least up-to-date
as the receiver's are eligble to receive a vote. The function returns both the vote decision and an
indication of whether a higher term was ibserved, allowing the caller to reset \texttt{votedFor} when necessary.

\subsubsection{Follower Role}
\texttt{doFollower} maintains the election time and processes two classes of events:
\begin{enumerate}
    \item \textbf{AppendEntries}: processes through \texttt{doCommonAE}. On success or on seeing
    higher term, resets election timer. If the leader's term is newer, clear \texttt{votedFor}
    \item \textbf{RequestVote}: process via \texttt{doCommonRV}. Reply and reset the timer.
\end{enumerate}
If the timer elapses without observed leader activity, node transitions to \texttt{CANDIDATE}.

\subsubsection{Candidate Role}
\texttt{doCandidate} increments \texttt{term} and self-votes, then issues parallel  \texttt{RequestVote}
RPCs vis \texttt{requestVotes(ctx)}.
Votes are aggregated on a channel of \texttt{VoteResult}. The candidate:
\begin{itemize}
    \item Becomes \texttt{LEADER} upon majority (strictly more than half of $N$).
    \item Reverts to \texttt{FOLLOWER} if any response carries a strictly higher term.
    \item Restarts the election with a fresh randomized timeout if it fails to gain a quorum.
    \item Rejects external vote requests for the current term because it already voted for itself,
            unless a higher term appears (abdication).
\end{itemize}

\subsubsection{Leader Role}
Upon entering \texttt{doLeader}, the node immediately asserts leadership by broadcasting
\textit{heartbeats} (AppendEntries with empty \texttt{Entires}) to all peers. A ticker
(\texttt{DEFAULT\_HEARTBEAT\_TIMEOUT}) triggers additional heartbeats periodically. Any
inbound AppendEntries with a higher term or RequestVote with a higher term causes abdication
to \texttt{FOLLOWER}. A short debug timer bounds the demo session for observability.

% --- INSERT DIAGRAMS HERE ---
\mmdfigure{raft-election}{Raft Leader Election State Machine\label{fig:raft-election}}
\mmdfigure{raft-rpc-flow}{Raft RPC Interaction During Election\label{fig:raft-rpc-flow}}
% --- END INSERT ---

\subsubsection{Outbound RPCs and Parallelism}
\texttt{sendHeartbeats} constructs a single immutable heartbeat request and invokes
\texttt{AppendEntries} on each \texttt{ElectionClient} concurrently. Results are pushed to a
shared \texttt{responses} channel.

\texttt{requestVotes} similarly fans out \texttt{RequestVote} calls. Results are wrapped in
\texttt{VoteResult} (peer id, grant bit, observed term, error) and gathered on a buffered channel.
A \texttt{WaitGroup} coordinates producer completion, after which the channel is closed.

\subsection{Log Module}
The \texttt{log} package procides a lightweight, generic implementation of Raft's replicated log abstraction.
It maintains an ordered sequence of log entries and two associated snapshots representing the state of the replicated state machine.

\subsubsection{Design Overview}
The core type \texttt{Log[E, S]} is a parameter over:
\begin{itemize}
    \item \textbf{E}: the entry type (application-specific commands).
    \item \textbf{S}: a type implementing the \texttt{Snapshot[E, S]} interface, representing the materialized state after applying entries.
\end{itemize}

Each log instance tracks:
\begin{itemize}
    \item \texttt{headSnapshot}: a snapshot representing the state up to the first entry in the log.
    \item \texttt{tailSnapshot}: a snapshot continously updates as new entries are appended.
    \item \texttt{realFirstIndex}: the global index of the first log entry after squashing or compaction.
    \item \texttt{entries}: an in-memory slice of remaining unapplied entries.
\end{itemize}

\subsubsection{Snapshot Interface}
The \texttt{Snapshot} interface defines two generic methods:
\begin{verbatim}
    ApplyEntry(Entry)
    Clone() Self
\end{verbatim}
\textbf{ApplyEntry} mutates the snapshot by applying an entry's effects, 
while \textbf{Clone} ensures that new logs or truncations can safely copy snapshot state.

\subsubsection{Log Initialization}
\texttt{NewLog(initialSnapshot, indexOffset)} creates a new log from an existing snapshot.
The constructor clones the snapshot for the head (persistent state) and it reuses it as the tail (mutable state).
The \texttt{realFirstIndex} tracks the absolute position of the first entry, allowing the log to appear contiguous across truncations.

\subsubsection{Appending Entries}
\texttt{Append(entry)} performs two actions atomically:
\begin{enumerate}
    \item Applies the new entry to the tail snapshot via \texttt{ApplyEntry}, keeping the in-memory snapshot consistent.
    \item Appends the entry to the \texttt{entries} slice.
\end{enumerate}
This ensures O(1) amortized append performance while keeping the latest snapshot always consistent with all entries applied so far.

\subsubsection(Snapshotting and Compaction)
To avoid excessive growth of the log, the Snapshot method supports selective compaction:
\begin{itemize}
    \item \texttt{SquashFirstN(n)} applies and removes the first \texttt{n} entries from the log, merging them into \texttt{headSnapshot} and incrementing \texttt{realFirstIndex}.
    \item \texttt{SquashUntil(predicate)} squashes all entries up to (but not including) the first entry matching the given predicate.
\end{itemize}
This method follow's Raft's snapshotting behavior (\S7 of the Raft paper) without persistent storage: once entries are safely replicated and applied by all follower, they can be compacted.

\subsubsection{Commit Point and Checkpoints}
Each server maintains a \texttt{commitPoint} object, which is a checkpoint over the replicated log. On startup we create an initial checkpoint at the index
immediately before the first log entry. As the leader observes that a given index has been replicated on a majority of servers, it advances the commit index
and calls \texttt{commitPoint.AdvanceTo(newIndex)}. This operation replays newly committed entries from the log into the \texttt{Tree} snapshot and updates
the internal cursor, so that subsequent advances are incremental rather than reapplying the entire log.

Because checkpoints are tied to the snapshot-aware log, followers recovering from a crash can resume from their last committed index without recomputing the full state from scratch,
and the commit path has a clear separation from the uncommitted tail fo the log.

\subsection{Watch Manager Implementation}
Our watch system is implemented by the \texttt{WatchManager}, which tracks a list of pending \texttt{Watch}es.
Each \texttt{Watch} consists of a \texttt{predicate} function $\left(\texttt{LogEntry}, \texttt{Index}\right) \rightarrow \texttt{bool}$
and a channel to be notified when the watch has occurred.

When a leader commits a new log entry, it passes that entry, along with that entry's index, to the \texttt{WatchManager}.
The \texttt{WatchManager} then checks all of its pending watches,
and any watches whose predicates match this new entry will be removed from the list and their corresponding channels will be notified.

\subsection{Transport and Peer Topology}
\texttt{connectToPeers} creates long-lived gRPC client stubs
(\texttt{raftpb.ElectionClient}) to all peers listed in \texttt{peers: map[NodeId]string}.
These stubs are stored in \texttt{s.peerConns}. 
Derp.\todo{}

\section{Demonstration}
\todo[inline]{Demonstration section}


\section{Performance}
\todo[inline]{Performance section}

\section{Testing}

To validate linearizability, monotonic reads, cross-node consistency, and failure recovery,
we designed a set of test cases across 3 to 5 node clusers. Each test is described with its setup, actions, observations,
and expected results.

\subsection{Linearizable Writes: Single-Leader Sequential Create/Update}
\textbf{Setup:} Three-node cluster. A Leader $L$ is elected. A client $C_1$ is connected to $L$.

\textbf{Actions:}
\begin{enumerate}
    \item $C_1$: \texttt{Create("/foo", "v1")}
    \item $C_1$: \texttt{SetData("/foo", "v2", -1)}
    \item $C_1$: \texttt{SetData("/foo", "v3", -1)}
    \item After each write, $C_1$ immediately issues \texttt{GetData("/foo")}.
\end{enumerate}

\textbf{Expected Result:} Reads return \emph{v1}, then \emph{v2}, then \emph{v3} in strict order.
No reordering, skipping or stale values.

\subsection{Linearizable Writes: Concurrent Writes Ordered by Leader}

\textbf{Setup:} Three-node cluster. Clients $C_1$ and $C_2$ connected to Leader $L$.

\textbf{Actions:} $C_1$ and $C_2$ concurrently issue \texttt{SetData("/bar", "A", -1)}
and \texttt{SetData("/bar", "B", -1)}.

\textbf{Observation:} After success, all clients read \texttt{GetData("/bar")} on $C_1$,
$C_2$, and follower $F$.

\textbf{Expected Result:} All nodes converge on a single final value in the leader's chosen
serialization order (either $A \rightarrow B$ or $B \rightarrow A$).
No interleaving or non-linearizable outcomes.

% \subsection{Monotonic Reads}
% \subsubsection{Test 3: Read-Only Client Monotonicity}
%
% \textbf{Setup:} Client $C_3$ reads from $F$. Leader $L$ performs updates.
%
% \textbf{Actions:}
% $L$: \texttt{SetData("/m", "1")} then \texttt{SetData("/m", "2")}.
% $C_3$ polls \texttt{GetData("/m)} every 100ms.
%
% \textbf{Expected Result:} Observed values are monotonic: once $C_3$ sees ``2'', it never
% returns ``1'' again. Temporary lag is allowed but regressions are not.

% \subsubsection{Test 4: Monotonic Reads Across Session Migration}
% 
% \textbf{Setup:} Client $C_4$ initially connected to follower $F_1$. Migrates mid-run to $F_2$.
% 
% \textbf{Actions:}
% $L$: \texttt{SetData("/n", "x")} then \texttt{SetData("/n", "y")}.
% $C_4$ reads \texttt{GetData("/n")} from $F_1$, migrates, then continues reading on $F_2$.
% 
% \textbf{Expected Result:} No backwards reads: after observing ``y'' on $F_1$, reads on 
% $F_2$ never return ``x''. Followers must not serve older states than those already observed.

% TODO
% \subsection{Cross-Node Consistency}
% \subsubsection{Test 5: Writes on Leader, Reads on All Nodes}
% 
% \textbf{Setup:} Five-node cluster. Clients $C_1\dots C5$ connected to different nodes.
% 
% \textbf{Actions:} Leader performs:
% \begin{enumerate}
%     \item \texttt{Create("/k"),"alpha"}.
%     \item \texttt{SetData("/k", "beta")}
% \end{enumerate}
% 
% \textbf{Observation:} All clients repeatedly read \texttt{GetData("/k")} for 5 seconds.
% 
% \textbf{Expected Result:} All nodes converge to ``beta''. No node returns a value outside the committed sequence.
% Temporary follower lag is acceptable.

\subsection{Leader Election: Killed Leader Causes Election}

\textbf{Setup:} Five-node cluster.

\textbf{Actions:}
\begin{enumerate}
    \item Start all five nodes.
    \item Wait for initial election to occur.
    \item Kill current leader node.
    \item Wait some time for election timeouts to occur.
    \item After that time has passed, there should be a new leader.
\end{enumerate}

\todo[inline]{observation, expected results}

\subsection{Leader Election: Restarting Enough Nodes Unblocks Election}

\textbf{Setup:} Five-node cluster.

\textbf{Actions:}
\begin{enumerate}
    \item Start all five nodes.
    \item Wait for initial election to occur.
    \item Kill current leader node and two additional follower nodes, leaving a total of $2$ of $5$ nodes alive.
    \item Wait some to see if a leader is elected.
    \item Restart one of the killed followers, bringing us back up to $3$ of $5$ nodes alive.
    \item Wait some additional time, and a leader should now actually be elected.
\end{enumerate}

\textbf{Observation:} On step 4, no leader should ever be elected. On step 6, a leader should be elected.

\textbf{Expected Result:} No leader is elected when there is not a majority alive.
Once there is a majority alive, there should eventually be a leader elected.


% \subsubsection{Failure Recovery}
% \subsubsection{Test 6: Leader Crash After Append, Before Commit}
% 
% \textbf{Setup:} Three-node cluster. Followers $F_1$, $F_2$.
% 
% \textbf{Actions:}
% Leader $L$ appends \texttt{SetData("/r", "new")} then crashes \emph{before} receiving a quorum ACK.
% 
% \textbf{Observation:} Reads on $F_1$ and $F_2$ via \texttt{GetData("/r)}.
% 
% \textbf{Expected Result:} Value remains the old value. The uncommitted write is discarded after new leader election. No 
% partial visibility.

% TODO
% \subsection{Quorum and Availability}
% \subsubsection{Test 7: Minority Partition Unavailable for Writes}
% 
% \textbf{Setup:} Five-node cluster partitioned into 3-node majority and 2-node minority.  
% 
% \textbf{Actions:} Clients attempt writes in both partitions.  
% 
% \textbf{Expected Result:}  
% \begin{itemize}
%   \item Majority partition continues serving writes normally.
%   \item Minority partition rejects or blocks writes.
%   \item Minority reads may lag or fail.
%   \item After healing, minority catches up from leader log.
% \end{itemize}

% TODO
% \subsubsection{Test 8: Node Join and Catch-Up}
% 
% \textbf{Setup:} Three nodes perform 100 sequential updates on \texttt{/z}.
% 
% \textbf{Actions:} Add new node $N_4$, allow it to synchronize.
% 
% \textbf{Expected Result:} After catch-up, $N_4$ returns the latest committed value.
% Log backfull converges without divergence.

% \subsection{Watches and Notifications}
% \subsubsection{Test 9: Watch Triggers on Immediate Children}
% AppendEntries Path (Follower \& Leader, \S5.3)
% \textbf{Setup:} Client registers a watch via \texttt{GetChildren("/p", watchChan)}.
% 
% \textbf{Actions:}
% Leader creates \texttt{/p/a}, then \texttt{/p/a/b}, then deletes \texttt{/p}.
% 
% \textbf{Expected Result:}
% Notifications fire for \texttt{/p/a} (child created) and \texttt{/p} (deleted).
% No notification for grandchild \texttt{/p/a/b}, consistent with Zookeeper semantics.

\subsection{Operational Parameters}
\begin{itemize}
    \item Cluster sizes tested: 3-node and 5-node.
    \item Timing: heartbeat interval and election timeout ranges.
    \item Failure modes: crash-stop, network partitions.
    \item Client placement: leader-connected vs. \ follower-connected vs. \ migrating.
    \item Metrics recorded: commit index progression, read sequences, convergence time, 
    leadership transitions.
\end{itemize}


\section{Conclusions}
\todo[inline]{Conclusions section}

\begin{thebibliography}{00}

\bibitem{zookeeper2010}
P.~Hunt, M.~Konar, F.~P.~Junqueira, and B.~Reed, 
``ZooKeeper: Wait-free coordination for Internet-scale systems,''
in \emph{Proc. 2010 USENIX Annual Technical Conference (USENIX ATC’10)}, 
Boston, MA, USA, Jun. 2010.

\bibitem{zookeeperUseCases}
Apache Software Foundation,
``ZooKeeper: Because coordinating distributed systems is a zoo,''
Accessed: Oct. 9, 2025. [Online]. Available:
\url{https://zookeeper.apache.org/doc/current/zookeeperUseCases.html}

\bibitem{raft2014}
D.~Ongaro and J.~Ousterhout,
``In search of an understandable consensus algorithm,'' 
in \emph{Proc. 2014 USENIX Annual Technical Conference (USENIX ATC’14)}, 
Philadelphia, PA, USA, Jun. 2014. 
[Online]. Available: 
\url{https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf}

\bibitem{kim2021}
D.~Kim, I.~Doh, and K.~Chae,
``Improved Raft algorithm exploiting federated learning for private blockchain performance enhancement,''
in \emph{Proc. 2021 International Conference on Information Networking (ICOIN)}, 
Jeju Island, South Korea, Jan. 2021, pp.~828--832. 
doi: \href{https://doi.org/10.1109/ICOIN50884.2021.9333932}{10.1109/ICOIN50884.2021.9333932}.

\bibitem{liu2022}
X.~Liu, Z.~Huang, Q.~Wang, and N.~Luo,
``An optimized key–value Raft algorithm for satisfying linearizable consistency,''
in \emph{Proc. 2022 Int. Conf. on Networking and Network Applications (NaNA)},  
Haikou, China, Dec. 2022, pp.~522--527.  
doi: \href{https://doi.org/10.1109/NaNA56854.2022.00096}{10.1109/NaNA56854.2022.00096}.

\bibitem{liu2023}
X.~Liu, Z.~Huang, and Q.~Wang,
``An optimized snapshot Raft algorithm for log compression,'' 
in \emph{Proc. 2023 2nd Int. Conf. on Artificial Intelligence and Blockchain Technology (AIBT)}, 
Chengdu, China, Jun. 2023, pp.~6--10.  
doi: \href{https://doi.org/10.1109/AIBT57480.2023.00008}{10.1109/AIBT57480.2023.00008}.

\bibitem{paznikov2020}
A.~A.~Paznikov, A.~V.~Gurin, and M.~S.~Kupriyanov,
``Implementation in actor model of leaderless decentralized atomic broadcast,''
in \emph{Proc. 2020 9th Mediterranean Conf. on Embedded Computing (MECO)}, 
Budva, Montenegro, Jun. 2020, pp.~1--4.  
doi: \href{https://doi.org/10.1109/MECO49872.2020.9134220}{10.1109/MECO49872.2020.9134220}.

\bibitem{sui2025}
X.~Sui, X.~Wang, and S.~Duan,
``Signature-free atomic broadcast with optimal $\mathcal{O}(n^{2})$ messages and $\mathcal{O}(1)$ expected time,'' 
in \emph{Proc. 2025 IEEE Symposium on Security and Privacy (SP)}, 
San Francisco, CA, USA, May 2025, pp.~1547--1565.  
doi: \href{https://doi.org/10.1109/SP61157.2025.00244}{10.1109/SP61157.2025.00244}.

\bibitem{mane2023}
S.~Mane, F.~Lyu, and B.~Reed,
``Verify, and then trust: Data inconsistency detection in ZooKeeper,'' 
in \emph{Proc. 10th Workshop on Principles and Practice of Consistency for Distributed Data (PaPoC ’23)}, 
Rome, Italy, May 2023, pp.~16--22.  
doi: \href{https://doi.org/10.1145/3578358.3591328}{10.1145/3578358.3591328}.

\end{thebibliography}

\end{document}

