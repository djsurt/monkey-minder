The goal of our project is to implement a distributed tree-based data store similar
to Apache ZooKeeper using Golang. Like ZooKeeper, our service guarantees linearizable 
writes while supporting read-heavy workloads by guaranteeing montonic reads.
Developing such a service involves implementing protocols for leader election, 
replication \& consistency, and Lamport timestamps to provide causal ordering.
The service must be fault-tolerant, robust to network partitions, and available to 
many concurrent clients.

For our implementation, we wanted to adhere to a few additional constraints. First,
we chose to use Golang as our programming environment. Golang adopts the
Communicating Sequential Processes (CSP) concurrency model, and we chose to fully
embrace this paradigm in our implementation by avoiding locks, semaphores, and other
concurrency primitives. Instead, we relied almost exclusively on Go's channel primitive
for managing concurrent access to shared resources.

Second, instead of Zab we chose to utilize the Raft consensus algorithm. While
Zab and Raft are both equivalent to Paxos \todo{CITE}, Raft is more recent algorithm
and used in popular services such as etcd and MongoDB \todo{CITE}. Additionally, 
Raft claims to be a more understandable alternative to Paxos, a property that proved
to make implementation easier. In order to use Raft, we had to relax its consistency
guaranatee for reads, which provides for linearizable reads by forwarding all requests
to the leader \cite{ongaro_search_2014}. ZooKeeper only provides monotonic reads from the perspective of 
individual clients. We modified our Raft implementation to allow reads to be served 
locally from each replica, enabling high throughput for read-dominant workloads.

Third, we chose to use gRPC and Protocol buffers as our transport layer. gRPC is
an RPC framework created by Google \todo{CITE}, and Protobufs are Google's language 
independent serialization framework \todo{CITE}. We chose these tools because they
enable our system to operate on hetereogeneous platforms. By building our service
as an RPC with Protobufs describing the serialization mechanism, we can leverage
the wide implementation of these tools in a variety of languages to extend our
client to other services. Additionally, both gRPC and Protbufs are popular in the 
industry, and we wanted to gain familiarity with tools we may use in our careers.

By building our project within these parameters, we hoped to gain practical
experience navigating the unique challenges posed by distributed systems.
